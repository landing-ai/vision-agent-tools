{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9968fc-11b3-4513-b277-67869a4d99f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from typing import Union, List, Dict, Any, Tuple, cast\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from vision_agent_tools.models.florence2_sam2 import Florence2SAM2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd926b2-5c8d-4f04-8a07-b118119d90b2",
   "metadata": {},
   "source": [
    "# Visualization tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8339e1e0-e5e6-4fa3-8310-ceb3834184dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = [\n",
    "    (158, 218, 229),\n",
    "    (219, 219, 141),\n",
    "    (23, 190, 207),\n",
    "    (188, 189, 34),\n",
    "    (199, 199, 199),\n",
    "    (247, 182, 210),\n",
    "    (127, 127, 127),\n",
    "    (227, 119, 194),\n",
    "    (196, 156, 148),\n",
    "    (197, 176, 213),\n",
    "    (140, 86, 75),\n",
    "    (148, 103, 189),\n",
    "    (255, 152, 150),\n",
    "    (152, 223, 138),\n",
    "    (214, 39, 40),\n",
    "    (44, 160, 44),\n",
    "    (255, 187, 120),\n",
    "    (174, 199, 232),\n",
    "    (255, 127, 14),\n",
    "    (31, 119, 180),\n",
    "]\n",
    "\n",
    "def _get_text_coords_from_mask(\n",
    "    mask: np.ndarray, v_gap: int = 10, h_gap: int = 10\n",
    ") -> Tuple[int, int]:\n",
    "    mask = mask.astype(np.uint8)\n",
    "    if np.sum(mask) == 0:\n",
    "        return (0, 0)\n",
    "\n",
    "    rows, cols = np.nonzero(mask)\n",
    "    top = rows.min()\n",
    "    bottom = rows.max()\n",
    "    left = cols.min()\n",
    "    right = cols.max()\n",
    "\n",
    "    if top - v_gap < 0:\n",
    "        if bottom + v_gap > mask.shape[0]:\n",
    "            top = top\n",
    "        else:\n",
    "            top = bottom + v_gap\n",
    "    else:\n",
    "        top = top - v_gap\n",
    "\n",
    "    return left + (right - left) // 2 - h_gap, top\n",
    "\n",
    "def overlay_segmentation_masks(\n",
    "    medias: Union[np.ndarray, List[np.ndarray]],\n",
    "    masks: Union[List[Dict[str, Any]], List[List[Dict[str, Any]]]],\n",
    "    draw_label: bool = True,\n",
    "    secondary_label_key: str = \"tracking_label\",\n",
    ") -> Union[np.ndarray, List[np.ndarray]]:\n",
    "    \"\"\"'overlay_segmentation_masks' is a utility function that displays segmentation\n",
    "    masks.\n",
    "\n",
    "    Parameters:\n",
    "        medias (Union[np.ndarray, List[np.ndarray]]): The image or frames to display\n",
    "            the masks on.\n",
    "        masks (Union[List[Dict[str, Any]], List[List[Dict[str, Any]]]]): A list of\n",
    "            dictionaries or a list of list of dictionaries containing the masks, labels\n",
    "            and scores.\n",
    "        draw_label (bool, optional): If True, the labels will be displayed on the image.\n",
    "        secondary_label_key (str, optional): The key to use for the secondary\n",
    "            tracking label which is needed in videos to display tracking information.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The image with the masks displayed.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "        >>> image_with_masks = overlay_segmentation_masks(\n",
    "            image,\n",
    "            [{\n",
    "                'score': 0.99,\n",
    "                'label': 'dinosaur',\n",
    "                'mask': array([[0, 0, 0, ..., 0, 0, 0],\n",
    "                    [0, 0, 0, ..., 0, 0, 0],\n",
    "                    ...,\n",
    "                    [0, 0, 0, ..., 0, 0, 0],\n",
    "                    [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
    "            }],\n",
    "        )\n",
    "    \"\"\"\n",
    "    medias_int: List[np.ndarray] = (\n",
    "        [medias] if isinstance(medias, np.ndarray) else medias\n",
    "    )\n",
    "    masks_int = [masks] if isinstance(masks[0], dict) else masks\n",
    "    masks_int = cast(List[List[Dict[str, Any]]], masks_int)\n",
    "\n",
    "    labels = set()\n",
    "    for mask_i in masks_int:\n",
    "        for mask_j in mask_i:\n",
    "            labels.add(mask_j[\"label\"])\n",
    "    color = {label: COLORS[i % len(COLORS)] for i, label in enumerate(labels)}\n",
    "\n",
    "    width, height = Image.fromarray(medias_int[0]).size\n",
    "    fontsize = max(12, int(min(width, height) / 40))\n",
    "    font = ImageFont.truetype(\"/home/ec2-user/code/vision-agent-tools/tmp/default_font_ch_en.ttf\",fontsize)\n",
    "\n",
    "    frame_out = []\n",
    "    for i, frame in enumerate(medias_int):\n",
    "        pil_image = Image.fromarray(frame.astype(np.uint8)).convert(\"RGBA\")\n",
    "        for elt in masks_int[i]:\n",
    "            mask = elt[\"mask\"]\n",
    "            label = elt[\"label\"]\n",
    "            tracking_lbl = elt.get(secondary_label_key, None)\n",
    "            np_mask = np.zeros((pil_image.size[1], pil_image.size[0], 4))\n",
    "            np_mask[mask > 0, :] = color[label] + (255 * 0.5,)\n",
    "            mask_img = Image.fromarray(np_mask.astype(np.uint8))\n",
    "            pil_image = Image.alpha_composite(pil_image, mask_img)\n",
    "\n",
    "            if draw_label:\n",
    "                draw = ImageDraw.Draw(pil_image)\n",
    "                text = tracking_lbl if tracking_lbl else label\n",
    "                text_box = draw.textbbox((0, 0), text=text, font=font)\n",
    "                x, y = _get_text_coords_from_mask(\n",
    "                    mask,\n",
    "                    v_gap=(text_box[3] - text_box[1]) + 10,\n",
    "                    h_gap=(text_box[2] - text_box[0]) // 2,\n",
    "                )\n",
    "                if x != 0 and y != 0:\n",
    "                    text_box = draw.textbbox((x, y), text=text, font=font)\n",
    "                    draw.rectangle((x, y, text_box[2], text_box[3]), fill=color[label])\n",
    "                    draw.text((x, y), text, fill=\"black\", font=font)\n",
    "        frame_out.append(np.array(pil_image))\n",
    "    return frame_out[0] if len(frame_out) == 1 else frame_out\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> Image.Image:\n",
    "    return Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "def rle_decode_array(rle: Dict[str, List[int]]) -> np.ndarray:\n",
    "    r\"\"\"Decode a run-length encoded mask. Returns numpy array, 1 - mask, 0 - background.\n",
    "\n",
    "    Parameters:\n",
    "        rle: The run-length encoded mask.\n",
    "    \"\"\"\n",
    "    size = rle[\"size\"]\n",
    "    counts = rle[\"counts\"]\n",
    "\n",
    "    total_elements = size[0] * size[1]\n",
    "    flattened_mask = np.zeros(total_elements, dtype=np.uint8)\n",
    "\n",
    "    current_pos = 0\n",
    "    for i, count in enumerate(counts):\n",
    "        if i % 2 == 1:\n",
    "            flattened_mask[current_pos : current_pos + count] = 1\n",
    "        current_pos += count\n",
    "\n",
    "    binary_mask = flattened_mask.reshape(size, order=\"F\")\n",
    "    return binary_mask\n",
    "\n",
    "def save_image(image: np.ndarray, file_path: str) -> None:\n",
    "    \"\"\"'save_image' is a utility function that saves an image to a file path.\n",
    "\n",
    "    Parameters:\n",
    "        image (np.ndarray): The image to save.\n",
    "        file_path (str): The path to save the image file.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "        >>> save_image(image)\n",
    "    \"\"\"\n",
    "    from IPython.display import display\n",
    "\n",
    "    if not isinstance(image, np.ndarray) or (\n",
    "        image.shape[0] == 0 and image.shape[1] == 0\n",
    "    ):\n",
    "        raise ValueError(\"The image is not a valid NumPy array with shape (H, W, C)\")\n",
    "\n",
    "    pil_image = Image.fromarray(image.astype(np.uint8)).convert(\"RGB\")\n",
    "    display(pil_image)\n",
    "    pil_image.save(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc9e31-f02f-40b9-ad86-cb628b2b5097",
   "metadata": {},
   "source": [
    "# Run inference on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f8b038-8d52-4665-821e-5fa6d407d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your image\n",
    "image_path = \"../tests/shared_data/images/tomatoes.jpg\"\n",
    "\n",
    "# Load the image\n",
    "image = load_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a92ae-d17a-46e5-89d9-e4fa8de4ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Florence2SAM2 instance\n",
    "florence2_sam2 = Florence2SAM2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70898011-c1ee-41fa-8444-6d53982066b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results = florence2_sam2(images=[image], prompt=\"tomato\")\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272dfb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe932d1e-e995-4fbd-8c88-c6075c54cf24",
   "metadata": {},
   "source": [
    "# Visulalize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78134b8b-35fa-4428-b125-16c6a94057ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "return_frame_data = []\n",
    "for frame_idx in range(len(results)):\n",
    "    annotations = len(results[frame_idx])\n",
    "    for annotation_idx in range(annotations):\n",
    "        annotation = results[frame_idx][annotation_idx]\n",
    "        mask = rle_decode_array(annotation[\"mask\"])\n",
    "        label = str(annotation[\"id\"]) + \": \" + annotation[\"label\"]\n",
    "        return_frame_data.append({\"label\": label, \"mask\": mask, \"score\": 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa3e48b9-03cc-4cc4-bfaa-ee4a5f882550",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_masks = overlay_segmentation_masks(np.asarray(image), return_frame_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39148eb3-267a-47b0-ab2c-33e93f12ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../tmp\", exist_ok=True)\n",
    "filepath = \"../tmp/segmented_tomato.jpg\"\n",
    "save_image(image_with_masks, filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-python3-kernel",
   "language": "python",
   "name": "my-python3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
